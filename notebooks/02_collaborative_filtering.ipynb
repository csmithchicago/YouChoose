{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/interim/small_10000_orders_weighted_adjacency_matrix.csv\")\n",
    "# df = df.sample(500)\n",
    "df[\"rating\"] = df.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df[[\"product_id\", \"weight\"]].groupby([\"product_id\"]).sum()\n",
    "df_grouped.reset_index(inplace=True)\n",
    "print(\n",
    "    f\"5 Most Purchased Products:\\n{df_grouped.sort_values(by='weight', ascending=False).head(5)}\"\n",
    ")\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "ax1.hist(df.weight, bins=50)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title(f\"Average Number of Purchases Per Order: {df.weight.mean():.2f}\")\n",
    "\n",
    "ax2.hist(df_grouped.weight, bins=50)\n",
    "ax2.set_title(\n",
    "    f\"Average Number of Times Each Product is Ordered: {df_grouped.weight.mean():.2f}\"\n",
    ")\n",
    "ax2.set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the models we will want to use a numeric index rather than the product_id and user_id so that we can easily match the embedding vector with the user or product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_sets = product_sets(df)\n",
    "\n",
    "# id_u_dict = list_to_indexed_dict(df.user_id)\n",
    "# id_p_dict = list_to_indexed_dict(df.product_id)\n",
    "\n",
    "# u_dict = {key: val for val, key in id_u_dict.items()}\n",
    "# p_dict = {key: val for val, key in id_p_dict.items()}\n",
    "# w_dict = {val: 1 for val in df.weight.unique()}\n",
    "\n",
    "# num_prods = len(p_dict)\n",
    "# num_negs = 5\n",
    "# idx = 5\n",
    "\n",
    "# df_s = df.sample(20)\n",
    "# user_ids = df_s[\"user_id\"].iloc[10]\n",
    "\n",
    "\n",
    "# def negative_sampling(num_negs, user_ids, prod_sets, p_dict, u_dict):\n",
    "#     \"\"\"\n",
    "#     Draw negative samples for each of the positive interactions.\n",
    "#     \"\"\"\n",
    "#     if isinstance(user_ids, np.int64):\n",
    "#         user_ids = [user_ids]\n",
    "\n",
    "#     u_list = []\n",
    "#     p_list = []\n",
    "#     r_list = num_negs * len(user_ids) * [0.]\n",
    "\n",
    "#     for u_id in user_ids:\n",
    "#         neg_set = set(p_dict.keys()) - prod_sets[u_id]\n",
    "#         neg_v = np.random.choice(tuple(neg_set), num_negs) \n",
    "\n",
    "#         for p_id in neg_v:\n",
    "#             u_list.append(u_dict[u_id])\n",
    "#             p_list.append(p_dict[p_id])\n",
    "\n",
    "#     return (torch.tensor(u_list), torch.tensor(p_list), torch.tensor(r_list))\n",
    "\n",
    "# u_samp = torch.from_numpy(pd.Series(df_s[\"user_id\"].iloc[:10]).map(u_dict).to_numpy())\n",
    "# p_samp = torch.from_numpy(pd.Series(df_s[\"product_id\"].iloc[:10]).map(p_dict).to_numpy())\n",
    "# w_samp = torch.from_numpy(pd.Series(df_s[\"rating\"].iloc[:10]).map(w_dict).to_numpy()).float()\n",
    "\n",
    "# negative_sampling(num_negs, user_ids, prod_sets, p_dict, u_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_sets(df):\n",
    "    \"\"\"\n",
    "    Generate sets for each user containing products that \n",
    "    they have previously purchased.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas DataFrame): Dataframe containing user_id and\n",
    "            product_id columns.\n",
    "    Return:\n",
    "        dictionary with user_id as keys and the product sets as values.\n",
    "    \"\"\"\n",
    "    df_g = (\n",
    "        df[[\"user_id\", \"product_id\"]]\n",
    "        .groupby([\"user_id\"])[\"product_id\"]\n",
    "        .agg(lambda x: set([val for val in x]))\n",
    "    )\n",
    "    df_g = df_g.reset_index()\n",
    "    df_g.columns = [\"user_id\", \"product_list\"]\n",
    "\n",
    "    return df_g.set_index(\"user_id\").to_dict()[\"product_list\"]\n",
    "\n",
    "\n",
    "def list_to_indexed_dict(list_):\n",
    "    \"\"\"\n",
    "    Assign id to distinct list elements and return \n",
    "    the id -> element mapping as a dictionary.\n",
    "    \"\"\"\n",
    "    return dict(enumerate(sorted(set(list_))))\n",
    "\n",
    "\n",
    "class RatingsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    User, product, ratings dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        product_dict,\n",
    "        user_dict,\n",
    "        dev=torch.device(\"cpu\"),\n",
    "        reweighting=dict(),\n",
    "        num_negs=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): Dataframe containing ratings.\n",
    "            product_dict (dict): Dictionary mapping product ids to indices.\n",
    "            user_dict (dict): Dictionary mapping user ids to indices.\n",
    "            reweighting (dict, optional): Dictionary mapping ratings to new values.\n",
    "            dev (torch device): Hardware that the model should run on.\n",
    "        \"\"\"\n",
    "        super(RatingsDataset, self).__init__()\n",
    "\n",
    "        if num_negs < 0:\n",
    "            raise ValueError(\"The number of negative samples must be positive.\")\n",
    "\n",
    "        self.df = dataframe\n",
    "        self.prod_sets = product_sets(dataframe)\n",
    "        self.p_dict = product_dict\n",
    "        self.u_dict = user_dict\n",
    "        self.w_dict = reweighting\n",
    "        self.num_prods = len(product_dict)\n",
    "        self.num_users = len(user_dict)\n",
    "        self.dev = dev\n",
    "        self.num_negs = num_negs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get and return Tensor for item, user, ratings triplet\n",
    "        \"\"\"\n",
    "        user_ids = self.df[\"user_id\"].iloc[idx]\n",
    "        item = self.transform(self.df[\"product_id\"].iloc[idx], self.p_dict)\n",
    "        user = self.transform(user_ids, self.u_dict)\n",
    "        rating = self.transform(self.df[\"rating\"].iloc[idx], self.w_dict).float()\n",
    "\n",
    "        if self.num_negs:\n",
    "            neg_i, users, neg_r = self.negative_sampling(user_ids)\n",
    "\n",
    "            item = torch.cat((item, neg_i))\n",
    "            user = torch.cat((user, users))\n",
    "            rating = torch.cat((rating, neg_r))\n",
    "\n",
    "        return (item, user, rating)\n",
    "\n",
    "    def transform(self, df_rows, mapping):\n",
    "        \"\"\"\n",
    "        Replace dataframe with index values and convert to torch.Tensor\n",
    "        \"\"\"\n",
    "        transformed = pd.Series(df_rows).replace(mapping).to_numpy()\n",
    "\n",
    "        return torch.from_numpy(transformed).to(self.dev)\n",
    "\n",
    "    def negative_sampling(self, user_ids):\n",
    "        \"\"\"\n",
    "        For each user interaction randomly sample products that they\n",
    "        have not previously purchased.\n",
    "        \"\"\"\n",
    "        if isinstance(user_ids, np.int64):\n",
    "            user_ids = [user_ids]\n",
    "\n",
    "        u_list = []\n",
    "        p_list = []\n",
    "        r_list = self.num_negs * len(user_ids) * [0.0]\n",
    "\n",
    "        for u_id in user_ids:\n",
    "            neg_set = set(self.p_dict.keys()) - self.prod_sets[u_id]\n",
    "            neg_v = np.random.choice(tuple(neg_set), self.num_negs)\n",
    "\n",
    "            for p_id in neg_v:\n",
    "                u_list.append(self.u_dict[u_id])\n",
    "                p_list.append(self.p_dict[p_id])\n",
    "\n",
    "        return (torch.tensor(p_list), torch.tensor(u_list), torch.tensor(r_list))\n",
    "\n",
    "\n",
    "def dataframe_split(df, train_frac=0.80, test_frac=0.10):\n",
    "    \"\"\"\n",
    "    Split dataframe into training, testing, and validation sets.\n",
    "    \"\"\"\n",
    "    train_df = df.sample(frac=train_frac, random_state=23)\n",
    "    test_df = df.drop(train_df.index).sample(int(test_frac * len(df)), random_state=23)\n",
    "    # All samples not in test or train sets are used for validation\n",
    "    val_df = df.drop(pd.concat([train_df, test_df], axis=0).index)\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \"\"\"Matrix factorization using pytorch.\"\"\"\n",
    "\n",
    "    def __init__(self, n_users, n_products, n_factors=20):\n",
    "        \"\"\"\n",
    "        Initalize the user and product embedding vectors in latent space.\n",
    "        \n",
    "        Args:\n",
    "            n_users (int): Number of users with prior purchases.\n",
    "            n_products (int): Total number of products purchased.\n",
    "            n_factors (integer, optional): Dimension of the latent embedding space.\n",
    "        \"\"\"\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.product_factors = nn.Embedding(n_products, n_factors)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.product_bias = nn.Embedding(n_products, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        \"\"\" \n",
    "        Matrix multiplication between user and product \n",
    "        embedding vectors.\n",
    "        \"\"\"\n",
    "        prediction = self.user_bias(user).squeeze() + self.product_bias(item).squeeze()\n",
    "        prediction += (\n",
    "            ((self.user_factors(user)) * (self.product_factors(item))).sum(2).squeeze()\n",
    "        )\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def prediction(self, user, item):\n",
    "        \"\"\"\n",
    "        Use product and user embedding vectors to calculate\n",
    "        a probability for positive interaction.\n",
    "        \"\"\"\n",
    "        activation = nn.Sigmoid()\n",
    "        prediction = self.user_bias(user).squeeze() + self.product_bias(item).squeeze()\n",
    "        prediction += (\n",
    "            ((self.user_factors(user)) * (self.product_factors(item))).sum(2).squeeze()\n",
    "        )\n",
    "        predict_pos = activation(prediction)\n",
    "        predict_neg = 1 - predict_pos\n",
    "\n",
    "        return torch.stack((predict_neg, predict_pos)).argmax(0).float()\n",
    "\n",
    "    def compute_loss(self, loss_fn, item, user, rating):\n",
    "        \"\"\"Calculate the loss of the predicted ratings.\"\"\"\n",
    "        return loss_fn(self.forward(user, item), rating.float().squeeze())\n",
    "\n",
    "    def compute_accuracy(self, data_loader):\n",
    "        \"\"\"\n",
    "        Compute the accuracy of our predictions against the true ratings.\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for item, user, true_rating in data_loader:\n",
    "                predicted = self.prediction(user, item)\n",
    "                total += predicted.numel()\n",
    "                correct += (predicted == true_rating).sum().item()\n",
    "\n",
    "        return total, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are only taking 500 interactions\n",
    "df_use = df.sample(500)\n",
    "num_negs = 15\n",
    "\n",
    "train_df, val_df, test_df = dataframe_split(\n",
    "    df_use\n",
    ")\n",
    "index_to_product_dict = list_to_indexed_dict(df_use.product_id)\n",
    "index_to_user_dict = list_to_indexed_dict(df_use.user_id)\n",
    "\n",
    "product_to_index_dict = {key: value for value, key in index_to_product_dict.items()}\n",
    "user_to_index_dict = {key: value for value, key in index_to_user_dict.items()}\n",
    "reweight_dict = {val: 1.0 for val in df_use.weight.unique()}\n",
    "\n",
    "n_users, n_products = len(user_to_index_dict), len(product_to_index_dict)\n",
    "\n",
    "train_data = RatingsDataset(\n",
    "    train_df,\n",
    "    product_to_index_dict,\n",
    "    user_to_index_dict,\n",
    "    reweighting=reweight_dict,\n",
    "    dev=dev,\n",
    "    num_negs=num_negs,\n",
    ")\n",
    "val_data = RatingsDataset(\n",
    "    val_df,\n",
    "    product_to_index_dict,\n",
    "    user_to_index_dict,\n",
    "    reweighting=reweight_dict,\n",
    "    dev=dev,\n",
    "    num_negs=num_negs,\n",
    ")\n",
    "test_data = RatingsDataset(\n",
    "    test_df,\n",
    "    product_to_index_dict,\n",
    "    user_to_index_dict,\n",
    "    reweighting=reweight_dict,\n",
    "    dev=dev,\n",
    "    num_negs=num_negs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = 50\n",
    "epochs = 100\n",
    "print_every = 5\n",
    "embedding_dim = 10\n",
    "l2_penalty = 0.001\n",
    "learning_rate = 1e-6\n",
    "\n",
    "model = MatrixFactorization(n_users, n_products, n_factors=embedding_dim)\n",
    "model.to(dev)\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=l2_penalty\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=bs)\n",
    "test_loader = DataLoader(test_data, batch_size=bs)\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for item, user, rating in train_loader:\n",
    "        loss = model.compute_loss(loss_fn, item, user, rating)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = [\n",
    "            model.compute_loss(loss_fn, item, user, rating).item()\n",
    "            for item, user, rating in val_loader\n",
    "        ]\n",
    "    val_loss = np.sum(val_loss)\n",
    "    val_total, val_correct = model.compute_accuracy(val_loader)\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(\n",
    "            f\"epoch #{epoch + 1}, training loss: {train_loss:0.3f}, \"\n",
    "            f\"validation loss: {val_loss:0.3f}, \"\n",
    "            f\"validation accuracy: {(100 * val_correct / val_total):.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "users_items = sigmoid(\n",
    "    model.user_factors.weight @ model.product_factors.weight.transpose(0, 1)\n",
    ")\n",
    "values = users_items.detach().numpy()\n",
    "\n",
    "plt.hist(values.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_item_for_user(model, user_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in [user_id] * len(items)])\n",
    "    item_ids = torch.LongTensor([item2idx[b] for b in items])\n",
    "\n",
    "    remove = set(ratings[ratings[user_col] == user_id][item_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_item = [\n",
    "        (p, b) for p, b in sorted(zip(preds, items), reverse=True) if b not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_item\n",
    "\n",
    "\n",
    "def recommend_user_for_item(model, item_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in users])\n",
    "    book_ids = torch.LongTensor([item2idx[b] for b in [item_id] * len(users)])\n",
    "\n",
    "    remove = set(ratings[ratings[item_col] == book_id][user_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_user = [\n",
    "        (p, u) for p, u in sorted(zip(preds, users), reverse=True) if u not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
