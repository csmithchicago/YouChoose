{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implicit\n",
    "So far we have only worked with implicit recommendations and so we need to convert the ratings/interactions to values 0/1. One way to do that is just setting everything a user rated as a interaction and try and predict if a user is likely to watch a movie, but give no indication about if they will like it or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "from sklearn.manifold import TSNE\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youchoose.data.data_loading import InteractionsDataset\n",
    "from youchoose.extraction.nn_latent_matrix_factorization import MatrixFactorization\n",
    "from youchoose.visualization.visualize import scatter, embedding_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie rating dataset\n",
    "df = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "col_names = df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample dataset for smaller training\n",
    "all_ = len(df)\n",
    "dataframe = df.sample(all_, random_state=23)  # here we are only taking 500 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "print_every = 5\n",
    "embedding_dim = 25\n",
    "l2 = 0.001\n",
    "lr = 0.01\n",
    "loss_fn = nn.MSELoss\n",
    "num_negs = 0\n",
    "bs = 250\n",
    "\n",
    "(tr_load, va_load, te_load), n_users, n_prod = InteractionsDataset.ratings_dataloader(\n",
    "    dataframe,\n",
    "    user_col=col_names[0],\n",
    "    item_col=col_names[1],\n",
    "    weight_col=col_names[2],\n",
    "    batch_size=bs,\n",
    "    dev=dev,\n",
    "    num_negs=num_negs,\n",
    "    shuffle_train=True,\n",
    "    reweight=True,\n",
    "    train_frac=0.80,\n",
    "    test_frac=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(\n",
    "        n_users, n_prod, n_factors=embedding_dim, lr=lr, l2=l2, loss_fn=loss_fn\n",
    "    ).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.create_user_item_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:27<11:09, 13.95s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-42843a560b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/perm-usb/coreys/Documents/instacart/youchoose/youchoose/extraction/nn_latent_matrix_factorization.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/perm-usb/coreys/Documents/instacart/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/perm-usb/coreys/Documents/instacart/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(epochs):\n",
    "    train_loss, train_accuracy = model.train_model(tr_load)\n",
    "    val_loss, val_accuracy = model.evaluate(va_load)\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(\n",
    "            f\"epoch #{epoch + 1}, \"\n",
    "            f\"training loss: {train_loss:0.3f}, \"\n",
    "            f\"training accuracy: {train_accuracy}, \"\n",
    "            f\"validation loss: {val_loss:0.3f}, \"\n",
    "            f\"validation accuracy: {val_accuracy}, \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe842f41da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(model.create_user_item_array().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "train_loss = 0\n",
    "total=0\n",
    "correct=0\n",
    "for user, item, rating in it.islice(tr_load, 2):\n",
    "    model.optimizer.zero_grad()\n",
    "\n",
    "    forward = model(user, item)\n",
    "    predicted = model._prob_to_class(forward)\n",
    "    loss = model.loss(forward, rating)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    total += predicted.numel()\n",
    "    correct += (predicted == rating).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward = model(user, item)\n",
    "predict_pos = model.activation(forward)\n",
    "predict_neg = 1 - predict_pos\n",
    "torch.stack((predict_neg, predict_pos)).argmax(0)#.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    item_emb = model.product_factors(item) + model.product_bias(item)\n",
    "    user_emb = model.user_factors(user) + model.user_bias(user)\n",
    "    mat_mult = (item_emb * user_emb).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_em = model.user_factors.weight.detach()\n",
    "item_em = model.product_factors.weight.detach()\n",
    "user_b = model.user_bias.weight.detach()\n",
    "item_b = model.product_bias.weight.detach()\n",
    "\n",
    "user_item_array = ((item_em + item_b) @ (user_em + user_b).transpose(0,1))\n",
    "post_probs = model.activation(user_item_array).numpy()\n",
    "post_preds = model._prob_to_class(user_item_array).numpy()\n",
    "\n",
    "post_movie_tsne = TSNE(random_state=23).fit_transform(model.product_factors.weight.detach().numpy())\n",
    "post_user_tsne = TSNE(random_state=23).fit_transform(model.user_factors.weight.detach().numpy())\n",
    "\n",
    "embedding_tsne(post_movie_tsne, post_user_tsne, [\"movies\", \"users\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embedding_tsne(pre_user_tsne, post_user_tsne, [\"pre user\", \"post users\"])\n",
    "embedding_tsne(pre_movie_tsne, post_movie_tsne, [\"pre movies\", \"post movie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_item_for_user(model, user_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in [user_id] * len(items)])\n",
    "    item_ids = torch.LongTensor([item2idx[b] for b in items])\n",
    "\n",
    "    remove = set(ratings[ratings[user_col] == user_id][item_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_item = [\n",
    "        (p, b) for p, b in sorted(zip(preds, items), reverse=True) if b not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_item\n",
    "\n",
    "\n",
    "def recommend_user_for_item(model, item_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in users])\n",
    "    book_ids = torch.LongTensor([item2idx[b] for b in [item_id] * len(users)])\n",
    "\n",
    "    remove = set(ratings[ratings[item_col] == book_id][user_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_user = [\n",
    "        (p, u) for p, u in sorted(zip(preds, users), reverse=True) if u not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTS = False\n",
    "\n",
    "if USE_WEIGHTS and Path(\"nn_model_epoch_1.pth\").exists():\n",
    "    model_save = torch.load(\"nn_model_epoch_1.pth\")\n",
    "\n",
    "    # before training user-item interaction matrix\n",
    "    user_em = model_save[\"user_factors.weight\"]\n",
    "    item_em = model_save[\"product_factors.weight\"]\n",
    "    user_b = model_save[\"user_bias.weight\"]\n",
    "    item_b = model_save[\"product_bias.weight\"]\n",
    "\n",
    "    user_item_array = ((item_em + item_b) @ (user_em + user_b).transpose(0,1))\n",
    "    pre_probs = model.activation(user_item_array).numpy()\n",
    "    pre_preds = model._prob_to_class(user_item_array).numpy()\n",
    "\n",
    "    pre_movie_tsne = TSNE(random_state=23).fit_transform(item_em)\n",
    "    pre_user_tsne = TSNE(random_state=23).fit_transform(user_em)\n",
    "\n",
    "    f, (ax1, ax2) = embedding_tsne(pre_movie_tsne, pre_user_tsne, [\"movies\", \"users\"])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
