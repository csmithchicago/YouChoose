{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.models.train_model import ratings_dataloader, MatrixFactorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/interim/small_10000_orders_weighted_adjacency_matrix.csv\")\n",
    "# df = df.sample(500)\n",
    "df[\"rating\"] = df.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df[[\"product_id\", \"weight\"]].groupby([\"product_id\"]).sum()\n",
    "df_grouped.reset_index(inplace=True)\n",
    "print(\n",
    "    f\"5 Most Purchased Products:\\n{df_grouped.sort_values(by='weight', ascending=False).head(5)}\"\n",
    ")\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "ax1.hist(df.weight, bins=50)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title(f\"Average Number of Purchases Per Order: {df.weight.mean():.2f}\")\n",
    "\n",
    "ax2.hist(df_grouped.weight, bins=50)\n",
    "ax2.set_title(\n",
    "    f\"Average Number of Times Each Product is Ordered: {df_grouped.weight.mean():.2f}\"\n",
    ")\n",
    "ax2.set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the models we will want to use a numeric index rather than the product_id and user_id so that we can easily match the embedding vector with the user or product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "print_every = 5\n",
    "embedding_dim = 10\n",
    "l2 = 0\n",
    "lr = 0.001\n",
    "# loss_fn = nn.BCEWithLogitsLoss\n",
    "loss_fn = nn.MSELoss\n",
    "dataframe = df.sample(500)  # here we are only taking 500 interactions\n",
    "num_negs = 0\n",
    "bs = 20\n",
    "\n",
    "(tr_load, va_load, te_load), n_users, n_prod = ratings_dataloader(dataframe, batch_size=bs, dev=dev, num_negs=num_negs)\n",
    "\n",
    "model = (\n",
    "    MatrixFactorization(\n",
    "        n_users, n_prod, n_factors=embedding_dim, lr=lr, l2=l2, loss_fn=loss_fn\n",
    "    )\n",
    ").to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = model.train_model(tr_load)\n",
    "    val_loss, val_accuracy = model.evaluate(va_load)\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(\n",
    "            f\"epoch #{epoch + 1}, \"\n",
    "            f\"training loss: {train_loss:0.3f}, \"\n",
    "            f\"training accuracy: {train_accuracy}, \"\n",
    "            f\"validation loss: {val_loss:0.3f}, \"\n",
    "            f\"validation accuracy: {val_accuracy}, \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "users_items = sigmoid(\n",
    "    model.user_factors.weight @ model.product_factors.weight.transpose(0, 1)\n",
    ")\n",
    "values = users_items.detach().numpy()\n",
    "\n",
    "plt.hist(values.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_item_for_user(model, user_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in [user_id] * len(items)])\n",
    "    item_ids = torch.LongTensor([item2idx[b] for b in items])\n",
    "\n",
    "    remove = set(ratings[ratings[user_col] == user_id][item_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_item = [\n",
    "        (p, b) for p, b in sorted(zip(preds, items), reverse=True) if b not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_item\n",
    "\n",
    "\n",
    "def recommend_user_for_item(model, item_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    m = model.eval().cpu()\n",
    "\n",
    "    user_ids = torch.LongTensor([user2idx[u] for u in users])\n",
    "    book_ids = torch.LongTensor([item2idx[b] for b in [item_id] * len(users)])\n",
    "\n",
    "    remove = set(ratings[ratings[item_col] == book_id][user_col].values)\n",
    "\n",
    "    preds = m(user_ids, item_ids).detach().numpy()\n",
    "    pred_user = [\n",
    "        (p, u) for p, u in sorted(zip(preds, users), reverse=True) if u not in remove\n",
    "    ]\n",
    "\n",
    "    return pred_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
